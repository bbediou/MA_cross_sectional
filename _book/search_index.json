[["metaana.html", "Chapter 5 Meta-analysis 5.1 Overall estimate 5.2 Moderator analysis 5.3 Publication bias", " Chapter 5 Meta-analysis Important Notes: - All analyses are done on the winsorized dataset (i.e., extreme values replaced distribution boundaries) - All clustering is done at the manuscript level. =&gt; This can be changed! Let me know if we should chat about these points! This can be important given that: - the same data has sometimes been published across several manuscripts - and some manuscripts contains different subject samples. 5.1 Overall estimate We use a multilevel meta-analytic model with robust variance estimates (RVE) for correlated and hierarchical effects (CHE) with small sample correction. The default correlation is set to 0.8 (default in RVE), and we use sensitivity analyses (see below) to test the impact of different values. The model includes a random factor for Papers and one for each effect sizes nested in papers. 5.1.1 Multilevel model (without RVE) ## ## Multivariate Meta-Analysis Model (k = 219; method: REML) ## ## Variance Components: ## ## estim sqrt nlvls fixed factor ## sigma^2.1 0.0222 0.1491 71 no Paper ## sigma^2.2 0.1130 0.3361 219 no Paper/ES_ID ## ## Test for Heterogeneity: ## Q(df = 218) = 953.5576, p-val &lt; .0001 ## ## Model Results: ## ## estimate se tval df pval ci.lb ci.ub ## 0.6238 0.0519 12.0124 218 &lt;.0001 0.5215 0.7262 *** ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Note that this model reports model-based (not robust) standard errors. The MLMA model reveals significant effect of AVG experience on cognition, with AVGPs outperforming NVGPs on cognitive tasks. Overall estimate: g = 0.624, p = &lt;.001 Residual heterogeneity is significant (QE(218) = 953.558, p = &lt;.001), suggesting possible moderating variables! 5.1.2 CHE model: Multilevel model with cluster-level RVE This new model for Correlated and Hierarchical Effects (CHE) is based on recent work from Pustejovsky &amp; Tipton (2021) as an extension of the range of RVE models. The CHE model was shown to better capture the types of data structure that occur in practice and –under some circumstances– to improve the efficiency of meta-regression estimates. ## Coef. Estimate SE t-stat d.f. (Satt) p-val (Satt) Sig. ## intrcpt 0.624 0.052 12 58.4 &lt;0.001 *** The cluster RVE is applied to adjust degrees of freedom and confidence intervals. The CHE model usually gives smaller SE indicating improved precision. 5.1.3 Standard RVE models with correlated or hierarchical weights For comparison with Bediou et al. 2018, we ran standard RVE models with correlated and hierarchical weights. ## RVE: Correlated Effects Model with Small-Sample Corrections ## ## Model: es_win ~ 1 ## ## Number of studies = 71 ## Number of outcomes = 219 (min = 1 , mean = 3.08 , median = 2 , max = 18 ) ## Rho = 0.8 ## I.sq = 53.5 ## Tau.sq = 0.129 ## ## Estimate StdErr t-value dfs P(|t|&gt;) 95% CI.L 95% CI.U Sig ## 1 X.Intercept. 0.669 0.0527 12.7 66 0 0.564 0.774 *** ## --- ## Signif. codes: &lt; .01 *** &lt; .05 ** &lt; .10 * ## --- ## Note: If df &lt; 4, do not trust the results ## RVE: Hierarchical Effects Model with Small-Sample Corrections ## ## Model: es_win ~ 1 ## ## Number of clusters = 71 ## Number of outcomes = 219 (min = 1 , mean = 3.08 , median = 2 , max = 18 ) ## Omega.sq = 0 ## Tau.sq = 0.106 ## ## Estimate StdErr t-value dfs P(|t|&gt;) 95% CI.L 95% CI.U Sig ## 1 X.Intercept. 0.524 0.062 8.45 26.1 0.00000000599 0.396 0.651 *** ## --- ## Signif. codes: &lt; .01 *** &lt; .05 ** &lt; .10 * ## --- ## Note: If df &lt; 4, do not trust the results Sensitivity analysis We test impact of different values of rho (correlation among dependent ES’s) on the overall estimates using a standard RVE model with correlated weights. ## RVE: Correlated Effects Model with Small-Sample Corrections ## Model: es_win ~ 1 ## ## Sensitivity Analysis ## ## Rho = 0 Rho = 0.2 Rho = 0.4 Rho = 0.6 Rho = 0.8 ## X.Intercept. Coefficient 0.6687 0.6688 0.6688 0.6688 0.6689 ## Std. Error 0.0527 0.0527 0.0527 0.0527 0.0527 ## Tau.sq Estimate 0.1282 0.1283 0.1285 0.1286 0.1287 ## Rho = 1 ## 0.6689 ## 0.0527 ## 0.1289 Overall estimate: g = 0.669, p = &lt;.001 Residual heterogeneity is significant (QE (218) = 953.558, p = &lt;.001), suggesting possible moderating variables! 5.1.4 univariate meta-analysis (for pub bias) We also ran univariate models to apply the more classical methods for detection and correction of publication bias. Because univariate models assume independent effect sizes, we first randomly selected one effect size per study (paper). ## ## Random-Effects Model (k = 71; tau^2 estimator: REML) ## ## tau^2 (estimated amount of total heterogeneity): 0.1185 (SE = 0.0409) ## tau (square root of estimated tau^2 value): 0.3442 ## I^2 (total heterogeneity / total variability): 51.84% ## H^2 (total variability / sampling variability): 2.08 ## ## Test for Heterogeneity: ## Q(df = 70) = 146.4369, p-val &lt; .0001 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## 0.6812 0.0595 11.4573 &lt;.0001 0.5647 0.7977 *** ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 5.1.5 Summary of overall effects Model beta SE CI_L CI_U tstat df pSignif RVE correlated 0.669 0.053 0.564 0.774 12.69 66.0 &lt;.001 RVE hierarchical 0.524 0.062 0.396 0.651 8.45 26.1 &lt;.001 CHE 0.624 0.052 0.520 0.728 12.00 58.4 &lt;.001 univariate 0.681 0.059 0.565 0.798 11.46 71.0 &lt;.001 Note. We pre-registered the CHE model as our primary model; other models are presented to show sensitivity of our results to various meta-analytic models. 5.2 Moderator analysis Moderator analysis is based on the multilevel model (i.e. mlma WITHOUT RVE) because the Wald_test is not compatible with the CHE model (i.e., mlma with RVE)… Our model includes moderators: - Cognitive domain (9 levels) - DV type: speed, accuracy (should we relabel as performance measure_ ?) - Effect: main (e.g., overall performance), interaction (e.g., difference score) - Recruitment: overt, covert 5.2.1 Compare RVE, CHE and SCE models Notes: - RVE = Robust Variance Estimate (effect sizes clustered by paper, correlated weights) - CHE = Correlated Hierarchical Weights (random effects multilevel model with RVE) - SCE = Subgroup Correlated Effects (alternative to running meta-analyses for each subgroup) =&gt; SCE RANDOM EFFECTS TO BE CHECKED BY MELISSA ! This analysis focuses on cognitive domain (primary moderator) and controls for other (secondary) moderators. The magnitude of the obtained estimates depends on the choice of reference levels for secondary moderators. The Wald Test of moderator effects test the relative differences between levels and is thus not sensitive to reference levels. However, to test if individual estimate differs from zero, we need to correct each estimate using the relative frequency of each moderator level in the dataset. Correlated effects Correlated hierarchical effects Sub-group correlated effects Coef Studies Effect sizes Est. [SE] Est. [SE] Est. [SE] tau perception 23 38 0.770 [0.135] 0.531 [0.140] 0.608 [0.158] 0.220 bottom up attention 4 7 -0.069 [0.183] 0.026 [0.172] -0.005 [0.192] 0.000 top down attention 44 74 0.668 [0.138] 0.461 [0.134] 0.591 [0.127] 0.327 inhibition 9 10 0.242 [0.149] 0.353 [0.148] 0.320 [0.155] 0.266 spatial cognition 16 27 0.561 [0.202] 0.476 [0.169] 0.471 [0.159] 0.255 multi tasking 11 24 0.497 [0.204] 0.641 [0.259] 0.595 [0.241] 0.505 verbal cognition 14 31 0.283 [0.178] 0.296 [0.151] 0.250 [0.143] 0.107 problem solving 6 8 0.134 [0.151] 0.141 [0.136] 0.120 [0.106] 0.000 tau 0.340 0.130 omega 0.325 Wald test p-value 0.003 0.110 0.010 All models include the following moderators and reference levels: - Cognitive domain: reference = perception - DV type: reference = accuracy - Effect type: reference = interaction - Recruitment: reference = covert Analyses of moderator effects are based on CHE model. Exploratory analyses using Subgroup Correlated Effects are also presented. 5.2.2 Tests of moderator effects (using CHE model) moderator test Fstat delta df_num df_denom p_val Cognitive domain HTZ 2.550 0.564 7 7.76 0.110 DV type HTZ 0.562 1.000 1 24.88 0.461 Effect HTZ 0.071 1.000 1 21.10 0.793 Recruitment HTZ 4.729 1.000 1 7.96 0.062 5.2.3 Estimates for each moderator level (different from zero?) moderator level k m g CI df pval LB UB pSignif Cognitive domain perception 38 23 0.700 0.517,0.883 23.44 0.000 0.517 0.883 &lt;.001 bottom-up attention 7 4 0.194 -0.179,0.567 3.21 0.203 -0.179 0.567 top-down attention 74 44 0.630 0.485,0.775 41.23 0.000 0.485 0.775 &lt;.001 inhibition 10 9 0.521 0.207,0.835 8.06 0.005 0.207 0.835 &lt;.01 spatial cognition 27 16 0.644 0.438,0.851 14.74 0.000 0.438 0.851 &lt;.001 multi-tasking 24 11 0.809 0.267,1.352 8.70 0.008 0.267 1.352 &lt;.01 verbal cognition 31 14 0.465 0.274,0.655 13.04 0.000 0.274 0.655 &lt;.001 problem solving 8 6 0.309 0.001,0.618 4.48 0.050 0.001 0.618 &lt;.05 DV type accuracy 118 49 0.633 0.508,0.757 43.80 0.000 0.508 0.757 &lt;.001 speed 101 45 0.582 0.459,0.705 37.06 0.000 0.459 0.705 &lt;.001 Effect interaction 63 26 0.590 0.388,0.792 24.60 0.000 0.388 0.792 &lt;.001 main 156 61 0.617 0.509,0.726 47.55 0.000 0.509 0.726 &lt;.001 Recruitment Covert 32 9 0.437 0.233,0.642 6.20 0.002 0.233 0.642 &lt;.01 Overt 187 65 0.639 0.527,0.751 55.23 0.000 0.527 0.751 &lt;.001 Notes: Estimates with degrees of freedom under 4 should not be interpreted and are thus highlighted. None of the moderators showed significant moderating influence according to AHT-F test (using clubSandwich::Wald_test) on the multilevel model (i.e., without RVE) except a marginal effect of recruitment. AVGPs outperformed NVGPs in irrespective of cognitive domain, DV type, effect or recruitment method: Cognitive domain: stronger effects for perception and multitasking, followed by top-down attention, spatial cognition and inhibition, and then verbal cognition. Marginal effect for problem solving and unreliable estimates (low df) for motor control and bottom-up attention. DV type: significant effects on speed and accuracy. Effect: significant group differences for both overall (main effect) performance measures and difference scores (interactions). Significant effect in both overtly and covertly recruited participants, with numerically larger effect for overt vs. covert. Residual heterogeneity is still significant (QE(208) = 866.71, p = ), suggesting additional moderating variables may be involved ! =&gt; Additional analyses are needed to understand where this comes from: publication bias / small study effect (adding variance or sda to moderator models?) lab / joint publication group single moderator models 5.3 Publication bias Numerous techniques exist for detecting and correcting publication bias. While methods for detecting publication bias (or small study effects) have improved largely over the past decades, it is not the case of correction methods such that estimating a unbiased (or publication-bias-corrected) estimate remains a challenge. The numerous methods available to date provide very heterogeneous estimates and will thus be reported in the form of sensitivity analysis as as recently recommended by Mathur &amp; VanderWeele (2020). Detection of publication bias was done for both: - The overall effect (intercept only model) and - The full model including all moderators Our main publication bias detection approach is based on Egger’s regression test with a modified precision covariate (Pustejovsky &amp; Rodgers, 2019). In addition, we use a number of additional methods to estimate the adjusted effect, because the estimates obtained from Eggers’s test (and PET-PEESE) are known to be unreliable. The best method for estimating the publication bias (or small-study) adjusted effect is based on the 3-parameter model selection (see below). 5.3.1 (contour-enhanced) Funnel plots Funnel plots are based on multilevel models without RVE, first for overall effect (i.e., intercept only) and then for the full model (i.e., with all moderators). In order to use trim and fill, we also conducted a univariate model using one randomly sampled estimate from each cluster. 5.3.2 Significance funnel plot (Mathur &amp; VanderWeele, 2020) This new type of graphical illustration was introduced recently as an alternative to funnel plots. Note: the line was drawn manually (i.e., no classification applied) with intercept = 0 and slope = 0.52. Non-affirmative studies have smaller point estimates than affirmative studies, suggesting that results may be sensitive to publication bias. 5.3.3 Egger’s regression with modified precision covariate This method is based on work from Pustejovsky and Rodgers (2018), and Rodgers &amp; Pustejovsky (2020). The new (Egger’s sandwich) test has been shown to maintain type I error (unlike the inflated type I errors commonly reported with other methods). Quote from Pustejovsky &amp; Rodgers 2020, page 36: “the Egger Sandwich is an acceptable, valid test for meta-analysis, but it must be interpreted with caution both because it has limited power to detect funnel plot asymmetry and because, in practice, such asymmetry may have other causes besides selective reporting.” “The Funnel Plot Test with MLMA maintains Type I error across nearly all conditions, and like the Egger Sandwich, it lacks power to detect funnel plot asymmetry.” We ran both Egger’s Sandwich and Egger’s MLMA models on both overall effect (intercept only) and full model with all moderators. method model term b se t dfs p ci.lb ci.ub Coef df_Satt Egger CHE (MLMA + RVE) NULL intrcpt -0.025 0.183 -0.134 13.3 0.895 -0.418 0.369 intrcpt 13.3 sda 1.845 0.535 3.452 18.4 0.003 0.724 2.966 sda 18.4 FULL intrcpt 0.002 0.199 0.010 19.4 0.992 -0.414 0.418 intrcpt 19.4 sda 1.768 0.638 2.772 22.0 0.011 0.445 3.091 sda 22.0 Egger Sandwich (RVE) NULL intrcpt -0.016 0.257 -0.064 11.9 0.950 -0.578 0.545 sda 2.015 0.726 2.778 14.8 0.014 0.467 3.563 FULL intrcpt 0.123 0.240 0.513 23.5 0.613 -0.372 0.618 sda 1.914 0.710 2.696 14.8 0.017 0.399 3.430 notes: - Terms: sda is the test of small-study effect; intercept is the corrected estimate - Models: NULL is the intercept-only model; FULL is the full moderator model Summary: The slope (sda) is significant indicating significant publication bias. The Intercept is not a reliable estimate of the bias-corrected effect (but shows how adding publication bias / small study affects the estimate). The other estimates can be ignored too as they are sensitive to choice of reference levels! Surprisingly, heterogeneity is still highly significant, even when including all moderators! =&gt; subgroup analyses? =&gt; moderators lab / joint publication group? =&gt; other suggestions…? 5.3.4 PET-PEESE Here, we applied PET and PEESE to our multilevel model with cluster robust variance (CHE model). For PEESE, we used the modified precision estimate because it increases precision. For comparison with Bediou et al., 2018, we also applied PET and PEESE to standard RVE models hierarchical weights and obtained similar results. In addition to the hierarchical weights used in Bediou et al. 2018, we also use correlated weights because they have been shown to perform significantly better in most situations. Again, we ran the analysis both on the overall effect (i.e., intercept only) model and on the full model with all moderators. Following Stanley &amp; Doucouliagos 2013, we use the conditional PET-PEESE estimate as follows: - If PET estimate is significant, we use PEESE estimate. - If PET is NS, then we use PET estimate. Note that this approach has been extensively criticized for its limitations, including by the authors themselves. Melissa recommended to drop PET-PEESE entirely because it is known to inflate type I error and has been consistently outperformed by the new precision estimate used by Egger Sandwich. I left them for comparison with Bediou et al. 2018. Click to see detailed results table! method model term b se t dfs p ci.lb ci.ub Coef df_Satt PET (RVE hier) NULL intrcpt -0.371 0.167 -2.216 6.19 0.067 -0.778 0.036 FULL intrcpt -0.313 0.162 -1.928 24.01 0.066 -0.648 0.022 NULL slope 2.700 0.472 5.721 9.83 0.000 1.646 3.755 FULL slope 2.998 0.543 5.518 18.50 0.000 1.859 4.137 PET (RVE corr) NULL intrcpt -0.261 0.219 -1.192 14.43 0.252 -0.729 0.207 FULL intrcpt -0.113 0.184 -0.616 23.70 0.544 -0.493 0.267 NULL slope 2.655 0.583 4.552 16.87 0.000 1.424 3.887 FULL slope 2.520 0.579 4.353 17.28 0.000 1.300 3.740 PET (CHE) NULL intrcpt -0.471 0.202 -2.331 15.68 0.033 -0.900 -0.042 intrcpt 15.68 FULL intrcpt -0.426 0.194 -2.196 20.39 0.040 -0.830 -0.022 intrcpt 20.39 NULL slope 3.161 0.548 5.769 19.74 0.000 2.017 4.304 sqrt(g_var) 19.74 FULL slope 3.183 0.635 5.014 22.55 0.000 1.868 4.498 sqrt(g_var) 22.55 PEESE (RVE hier) NULL intrcpt 0.091 0.094 0.962 6.55 0.370 -0.136 0.317 FULL intrcpt 0.193 0.133 1.447 22.15 0.162 -0.083 0.469 NULL slope 3.628 0.773 4.695 7.31 0.002 1.816 5.439 FULL slope 3.666 1.021 3.589 6.88 0.009 1.242 6.089 PEESE (RVE corr) NULL intrcpt 0.227 0.128 1.772 12.45 0.101 -0.051 0.504 FULL intrcpt 0.342 0.148 2.303 18.32 0.033 0.030 0.653 NULL slope 3.355 0.930 3.609 7.63 0.007 1.193 5.516 FULL slope 3.143 0.904 3.476 7.62 0.009 1.040 5.246 PEESE (CHE) NULL intrcpt 0.188 0.189 0.995 10.33 0.342 -0.231 0.608 intrcpt 10.33 FULL intrcpt 0.186 0.164 1.137 18.38 0.270 -0.157 0.530 intrcpt 18.38 NULL slope 3.328 1.488 2.237 5.64 0.069 -0.369 7.025 g_var 5.64 FULL slope 3.268 1.538 2.125 5.56 0.081 -0.569 7.106 g_var 5.56 5.3.5 Univariate methods (boostrapped) 5.3.5.1 Bootstrapped trim and fill (Duval &amp; Tweedie, 2001) Trim and fill, p-uniform and 3-PSM work only with independent effect sizes. In order to run these analyses, we thus randomly picked one effect size per study (i.e. paper). To verify that this random sampling does not introduce bias, we first checked the distribution of the overall effect obtained from 1000 bootstrapped samples of one effect size per paper. The univariate meta-analysis of 71 randomly selected independent effect sizes revealed an average overall effect of mean g = 0.663 (SD = 0.028) ## term b se ci.lb ci.ub ## 1 intrcpt 0.496 0.0294 0.441 0.558 Across the 1000 bootstrapped samples, trim and fill analysis imputed between 11 and 20 additional effects on the left side of the funnel plot (median = 16), in order to correct for its asymmetry. These additional studies decreased the overall estimate to a mean of g = 0.496 (SD = 0.029), but did not alter significance all p’s &lt; .001). 5.3.5.2 P-Uniform (van Assen, van Aert &amp; Wicherts, 2015) p-uniform is fundamentally similar to a p-curve that estimates the true effect using only significant effects. This method is not without limitations; it tends to overestimate effect sizes when heterogeneity is moderate to large, and is insensitive to p-values that are close to significance, or in the presence of p-hacking (Van Aerts, Wicherts &amp; van Assen, 2016). ## term b se ci.lb ci.ub ## 1 intrcpt 0.715 0.035 0.645 0.779 Studies with lower p values are observed less often than expected, whereas studies with high p values are more frequent than expected. Yet, the test of publication bias is not significant (pval = 1). 5.3.5.3 3-Parameter Selection Model (3PSM, Hedges &amp; Vevea 1996). Selection models are a general class of models that attempt to model the process by which the studies included in a meta-analysis may have been influenced by some form of publication bias. If a particular selection model is an adequate approximation for the underlying selection process, then the model provides estimates of the parameters of interest (e.g., the average true outcome and the amount of heterogeneity in the true outcomes) that are ‘corrected’ for this selection process (i.e., they are estimates of the parameters in the population of studies before any selection has taken place). PSM Using selmodel function from metafor This function allows to test different models. Colours show different (model-based) selective reporting biases: - Negexpm and logistic selection give identical results. - Step, halfnorm and Power give different results. 3-PSM Using weightfunc from weightr Here we focus on the 3-PSM approach, which models publication bias with 3-parameters. The first one represents how much less likely a non-significant result is to be published than a significant result. The other two parameters represent the estimated bias-adjusted mean effect and the estimated heterogeneity of the effects. Below we plot the distribution of estimates corrected for publication bias that are obtained from 100 bootstrapped samples with different thresholds for selective reporting ranging from 0.1 to 0.001. 5.3.6 Summary of publication-bias-corrected estimates method model term b se ci.lb ci.ub t dfs p pSignif PET (CHE) NULL intrcpt -0.471 0.202 -0.900 -0.042 -2.331 15.68 0.033 &lt;.05 FULL intrcpt -0.426 0.194 -0.830 -0.022 -2.196 20.39 0.040 &lt;.05 PET (RVE hier) NULL intrcpt -0.371 0.167 -0.778 0.036 -2.216 6.19 0.067 . FULL intrcpt -0.313 0.162 -0.648 0.022 -1.928 24.01 0.066 . PET (RVE corr) NULL intrcpt -0.261 0.219 -0.729 0.207 -1.192 14.43 0.252 FULL intrcpt -0.113 0.184 -0.493 0.267 -0.616 23.70 0.544 Egger CHE (MLMA + RVE) NULL intrcpt -0.025 0.183 -0.418 0.369 -0.134 13.32 0.895 Egger Sandwich (RVE) intrcpt -0.016 0.257 -0.578 0.545 -0.064 11.89 0.950 Egger CHE (MLMA + RVE) FULL intrcpt 0.002 0.199 -0.414 0.418 0.010 19.39 0.992 3-PSM intrcpt 0.086 0.025 0.047 0.145 PEESE (RVE hier) NULL intrcpt 0.091 0.094 -0.136 0.317 0.962 6.55 0.370 Egger Sandwich (RVE) FULL intrcpt 0.123 0.240 -0.372 0.618 0.513 23.48 0.613 3-PSM NULL intrcpt 0.132 0.032 0.085 0.214 PEESE (CHE) FULL intrcpt 0.186 0.164 -0.157 0.530 1.137 18.38 0.270 NULL intrcpt 0.188 0.189 -0.231 0.608 0.995 10.33 0.342 PEESE (RVE hier) FULL intrcpt 0.193 0.133 -0.083 0.469 1.447 22.15 0.162 PEESE (RVE corr) NULL intrcpt 0.227 0.128 -0.051 0.504 1.772 12.45 0.101 FULL intrcpt 0.342 0.148 0.030 0.653 2.303 18.32 0.033 &lt;.05 trim and fill NULL intrcpt 0.496 0.029 0.441 0.558 p-uniform intrcpt 0.715 0.035 0.645 0.779 Note: models are sorted from lower to higher estimate; background colour differentiates between full and null models. - Trim and fill, p-uniform and 3-PSM rely on independent effect sizes (randomly selected from each paper). - p values rely on different tests depending on the exact publication bias method and model used. - For p-uniform, SE corresponds to the difference between the upper and lower bounds of confidence interval. - For 3-PSM, the mean is the average and the SE is the standard deviation of estimates across 100 bootstrapped samples. Across all analyses, the slope (tests of small-study effect / publication bias) was always significant. The unbiased or corrected (i.e. publication-bias free) estimates vary tremendously and are thus reported as a form of a sensitivity analysis. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
